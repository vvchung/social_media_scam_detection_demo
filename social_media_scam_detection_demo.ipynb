{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 社群早期詐騙偵測演示\n",
        "\n",
        "這個參考「[一年臺灣民眾被詐騙一千億，得覺醒](https://medium.com/@bohachu/%E4%B8%80%E5%B9%B4%E8%87%BA%E7%81%A3%E6%B0%91%E7%9C%BE%E8%A2%AB%E8%A9%90%E9%A8%99%E4%B8%80%E5%8D%83%E5%84%84-%E5%BE%97%E8%A6%BA%E9%86%92-11ba5b6ec18e)」文章的 Colab 檔案，模擬完整的端到端（End-to-end）詐騙偵測流程，包含：\n",
        "\n",
        "*   **資料抓取**：\n",
        "模擬從社群平台（如 Facebook、LINE）API 接收資料。\n",
        "*   **圖-文多模態特徵工程**：\n",
        "分別從成員結構（Graph）與貼文文字（Text）提取特徵。\n",
        "*   **詐騙社群預測**：\n",
        "結合圖與文字特徵，訓練一個 LightGBM 模型來預測詐騙分數。\n",
        "*   **自動化處置**：\n",
        "根據預測分數，執行相對應的降溫或標記策略。"
      ],
      "metadata": {
        "id": "45d118e0"
      },
      "id": "45d118e0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b108bf",
      "metadata": {
        "id": "e1b108bf"
      },
      "outputs": [],
      "source": [
        "# @title 步驟一：環境設定與套件安裝\n",
        "\n",
        "!pip install -q pandas numpy scikit-learn lightgbm networkx matplotlib seaborn\n",
        "!pip install -q transformers sentence-transformers\n",
        "\n",
        "print(\"✅ 套件安裝完成！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "309ab043",
      "metadata": {
        "id": "309ab043"
      },
      "outputs": [],
      "source": [
        "# @title 步驟二：模擬資料產生\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "def generate_graph_features(is_scam=False):\n",
        "    \"\"\" 產生圖徵（Graph Features） \"\"\"\n",
        "    if is_scam:\n",
        "        # 詐騙社群：星狀擴散，一個核心節點連接大量新節點\n",
        "        G = nx.star_graph(n=np.random.randint(50, 200))\n",
        "        # 增加一些隨機邊來模擬複雜度\n",
        "        for i in range(int(G.number_of_nodes() / 10)):\n",
        "            u, v = np.random.choice(G.nodes(), 2, replace=False)\n",
        "            G.add_edge(u, v)\n",
        "\n",
        "        centrality = nx.degree_centrality(G)\n",
        "        core_node = max(centrality, key=centrality.get)\n",
        "        core_ness = centrality[core_node]\n",
        "        burstiness = np.random.uniform(0.8, 1.0) # 爆發指數高\n",
        "    else:\n",
        "        # 正常社群：隨機網路，節點平均連接\n",
        "        G = nx.erdos_renyi_graph(n=np.random.randint(50, 200), p=0.1)\n",
        "        core_ness = np.mean(list(nx.degree_centrality(G).values()))\n",
        "        burstiness = np.random.uniform(0.1, 0.4) # 爆發指數低\n",
        "\n",
        "    return core_ness, burstiness\n",
        "\n",
        "def generate_text_features(is_scam=False):\n",
        "    \"\"\" 產生文字特徵（Text Features） \"\"\"\n",
        "    scam_keywords = [\"高收益\", \"老師帶單\", \"保證獲利\", \"飆股\", \"內線消息\"]\n",
        "    normal_keywords = [\"美食分享\", \"旅遊心得\", \"寵物日常\", \"電影推薦\", \"二手交換\"]\n",
        "\n",
        "    if is_scam:\n",
        "        text = \" \".join(np.random.choice(scam_keywords, 5, replace=True))\n",
        "        hit_ratio = np.random.uniform(0.6, 1.0) # 關鍵字命中率高\n",
        "    else:\n",
        "        text = \" \".join(np.random.choice(normal_keywords, 5, replace=True))\n",
        "        hit_ratio = np.random.uniform(0.0, 0.2) # 關鍵字命中率低\n",
        "\n",
        "    return text, hit_ratio\n",
        "\n",
        "# --- 產生模擬資料 ---\n",
        "data = []\n",
        "for i in range(1000): # 產生 1000 筆社群資料\n",
        "    is_scam = True if np.random.rand() > 0.7 else False # 30% 是詐騙社群\n",
        "\n",
        "    core_ness, burstiness = generate_graph_features(is_scam)\n",
        "    text, hit_ratio = generate_text_features(is_scam)\n",
        "\n",
        "    data.append({\n",
        "        \"group_id\": f\"group_{i:04d}\",\n",
        "        \"text\": text,\n",
        "        \"core_ness\": core_ness,\n",
        "        \"burstiness\": burstiness,\n",
        "        \"keyword_hit_ratio\": hit_ratio,\n",
        "        \"is_scam\": 1 if is_scam else 0\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"模擬資料集（前 5 筆）:\")\n",
        "print(df.head())\n",
        "print(\"\\n資料集維度:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 步驟三：文字特徵嵌入 (Text Embedding)\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 載入一個輕量的多語言模型作為範例\n",
        "# 這邊我們用 sentence-transformers 內建模型來模擬 E5-moko 的效果\n",
        "model_name = 'distiluse-base-multilingual-cased-v1'\n",
        "text_embedder = SentenceTransformer(model_name)\n",
        "\n",
        "print(\"正在將貼文文字轉換為向量...\")\n",
        "# 對所有貼文進行 embedding\n",
        "text_embeddings = text_embedder.encode(df['text'].tolist(), show_progress_bar=True)\n",
        "\n",
        "print(\"✅ 文字嵌入完成！\")\n",
        "print(\"嵌入向量維度:\", text_embeddings.shape)"
      ],
      "metadata": {
        "id": "PWO7nanG5abn"
      },
      "id": "PWO7nanG5abn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 步驟四：特徵整合與模型訓練\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. 整合所有特徵\n",
        "graph_features = df[['core_ness', 'burstiness', 'keyword_hit_ratio']].values\n",
        "X = np.concatenate([graph_features, text_embeddings], axis=1)\n",
        "y = df['is_scam'].values\n",
        "\n",
        "# 2. 切分訓練集與測試集，並保留原始索引\n",
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
        "    X, y, df.index, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"訓練集維度: {X_train.shape}\")\n",
        "print(f\"測試集維度: {X_test.shape}\")\n",
        "\n",
        "# 3. 訓練 LightGBM 模型\n",
        "lgb_classifier = lgb.LGBMClassifier(objective='binary', random_state=42)\n",
        "lgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n✅ 模型訓練完成！\")\n",
        "\n",
        "# 4. 評估模型成效\n",
        "y_pred_proba = lgb_classifier.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_pred_proba > 0.5).astype(int) # 用 0.5 作為閥值\n",
        "\n",
        "print(\"\\n--- 模型評估報告 ---\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "\n",
        "# 繪製混淆矩陣\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fMa48jwt5hXA"
      },
      "id": "fMa48jwt5hXA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 步驟五：建立自動化處置策略\n",
        "\n",
        "def automated_disposal_strategy(group_id, score):\n",
        "    \"\"\"\n",
        "    根據詐騙分數執行自動化處置策略\n",
        "    \"\"\"\n",
        "    print(f\"--- 正在分析社群: {group_id} (詐騙分數: {score:.4f}) ---\")\n",
        "\n",
        "    if score > 0.9:\n",
        "        print(\"🔴 高風險！執行處置...\")\n",
        "        # throttle_reach(): 降低觸及率 90%\n",
        "        print(\"  - 執行 throttle_reach(): 觸及率 -90%\")\n",
        "        # flag_for_review(): 標記給人工審查\n",
        "        print(\"  - 執行 flag_for_review(): 已提交人工審查\")\n",
        "\n",
        "    elif score > 0.8:\n",
        "        print(\"🟡 中風險！執行處置...\")\n",
        "        # show_interstitial_warning_banner(): 顯示警告橫幅\n",
        "        print(\"  - 執行 show_interstitial_warning_banner(): 已對使用者顯示警告橫幅\")\n",
        "    else:\n",
        "        print(\"🟢 低風險。無需操作。\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# --- 模擬對新的社群資料進行即時偵測 ---\n",
        "print(\"🚀 開始模擬即時偵測新進社群...\\n\")\n",
        "\n",
        "# 從測試集中隨機抽取 5 個樣本來示範\n",
        "sample_indices = np.random.choice(len(X_test), 5, replace=False)\n",
        "sample_features = X_test[sample_indices]\n",
        "# Use the stored test_indices to select from the original DataFrame\n",
        "sample_info = df.loc[test_indices[sample_indices]]\n",
        "\n",
        "# 使用訓練好的模型進行預測\n",
        "predicted_scores = lgb_classifier.predict_proba(sample_features)[:, 1]\n",
        "\n",
        "# 執行自動化策略\n",
        "for i, (index, row) in enumerate(sample_info.iterrows()):\n",
        "    group_id = row['group_id']\n",
        "    score = predicted_scores[i]\n",
        "    automated_disposal_strategy(group_id, score)"
      ],
      "metadata": {
        "id": "hiv03dhsGpAY"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hiv03dhsGpAY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "這個 Colab 檔案提供了一個從資料模擬到模型訓練，再到自動化策略應用的完整範例。您可以根據這個框架，替換成真實世界的數據和更複雜的模型，以應對實際的詐騙偵測挑戰。"
      ],
      "metadata": {
        "id": "D4SlalYnHLhW"
      },
      "id": "D4SlalYnHLhW"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}